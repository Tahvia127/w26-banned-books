{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test collection...\n",
      "Testing: Gender Queer\n",
      "Result: {'book_title': 'Gender Queer', 'ban_date': '2022-09-01', 'avg_search_before': np.float64(40.23), 'avg_search_after': np.float64(28.9), 'max_search_before': np.int64(100), 'max_search_after': np.int64(100), 'min_search_before': np.int64(20), 'min_search_after': np.int64(14), 'percent_change': np.float64(-28.17), 'absolute_change': np.float64(-11.33), 'volatility': np.float64(15.17), 'data_collected': '2026-01-22 14:08:33', 'collection_successful': True}\n",
      "\n",
      "Testing: All Boys Aren't Blue\n",
      "Result: {'book_title': \"All Boys Aren't Blue\", 'ban_date': '2022-10-15', 'avg_search_before': np.float64(4.68), 'avg_search_after': np.float64(4.18), 'max_search_before': np.int64(100), 'max_search_after': np.int64(100), 'min_search_before': np.int64(0), 'min_search_after': np.int64(0), 'percent_change': np.float64(-10.69), 'absolute_change': np.float64(-0.5), 'volatility': np.float64(17.0), 'data_collected': '2026-01-22 14:08:47', 'collection_successful': True}\n",
      "\n",
      "Testing: The Bluest Eye\n",
      "Result: {'book_title': 'The Bluest Eye', 'ban_date': '2022-08-20', 'avg_search_before': np.float64(19.61), 'avg_search_after': np.float64(37.18), 'max_search_before': np.int64(100), 'max_search_after': np.int64(100), 'min_search_before': np.int64(0), 'min_search_after': np.int64(0), 'percent_change': np.float64(89.58), 'absolute_change': np.float64(17.57), 'volatility': np.float64(24.72), 'data_collected': '2026-01-22 14:09:43', 'collection_successful': True}\n",
      "\n",
      "Test results saved to ../data/raw/test_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Trends Data Collection Script\n",
    "Collects search volume data for banned books\n",
    "Author: Kevin (Google Trends Specialist)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "'''\n",
    "pandas: data tables (DataFrames).\n",
    "\n",
    "pytrends: unofficial Google Trends API.\n",
    "\n",
    "time: for sleep delays (avoids rate limits).\n",
    "\n",
    "datetime/timedelta: for date math around ban dates.\n",
    "\n",
    "numpy: numerical operations (mean, std, etc.).\n",
    "\n",
    "tqdm: progress bars.\n",
    "\n",
    "logging: records successes/failures to a log file.\n",
    "\n",
    "'''\n",
    "\n",
    "# Set up logging\n",
    "\n",
    "'''\n",
    "Creates a log file that:\n",
    "\n",
    "Records timestamps,\n",
    "\n",
    "Notes whether each book succeeds or fails,\n",
    "\n",
    "Helps you debug errors later without printing everything to the console.\n",
    "\n",
    "'''\n",
    "logging.basicConfig(\n",
    "    filename='data_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Initialize pytrends\n",
    "''' \n",
    "hl: English (U.S.) interface\n",
    "tz = timezone: for us in EST\n",
    "\n",
    "'''\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "def get_trends_data(book_title, ban_date_str, retries=3):\n",
    "    \"\"\"\n",
    "    Collect Google Trends data for a book around its ban date\n",
    "    \n",
    "    Parameters:\n",
    "    - book_title: String, the book title to search\n",
    "    - ban_date_str: String in format 'YYYY-MM-DD'\n",
    "    - retries: Number of times to retry if request fails\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with before/after search volumes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert ban date string to datetime: allows Python to actually work with our dates\n",
    "    try:\n",
    "        ban_date = datetime.strptime(ban_date_str, '%Y-%m-%d')\n",
    "    except:\n",
    "        logging.error(f\"Invalid date format for {book_title}: {ban_date_str}\")\n",
    "        return None\n",
    "    \n",
    "    # Define time periods: analyzing 3 months (90 days) before and after ban.\n",
    "    before_start = ban_date - timedelta(days=90)\n",
    "    before_end = ban_date - timedelta(days=1)\n",
    "    after_start = ban_date + timedelta(days=1)\n",
    "    after_end = ban_date + timedelta(days=90)\n",
    "    \n",
    "    # Format dates for pytrends: in this format, our data is compatible with Google Trends\n",
    "    before_timeframe = f\"{before_start.strftime('%Y-%m-%d')} {before_end.strftime('%Y-%m-%d')}\"\n",
    "    after_timeframe = f\"{after_start.strftime('%Y-%m-%d')} {after_end.strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    # Try collecting data with retries (prevents script from crashing from a bad book)\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # Get BEFORE ban data\n",
    "            '''\n",
    "            Requests Google Trends interest for that book title.\n",
    "\n",
    "            Restricts to the U.S.\n",
    "\n",
    "            Returns a DataFrame with weekly search interest scores (0 - 100 scale). \n",
    "\n",
    "            '''\n",
    "            pytrends.build_payload([book_title], timeframe=before_timeframe, geo='US')\n",
    "            before_df = pytrends.interest_over_time()\n",
    "\n",
    "            #If data exists, compute summary statistics. If Google returns nothing â†’ treat as zero interest\n",
    "            if not before_df.empty and book_title in before_df.columns:\n",
    "                before_values = before_df[book_title].values\n",
    "                before_avg = np.mean(before_values)\n",
    "                before_max = np.max(before_values)\n",
    "                before_min = np.min(before_values)\n",
    "            else:\n",
    "                before_avg = before_max = before_min = 0\n",
    "            \n",
    "            # Wait to avoid rate limiting\n",
    "            time.sleep(12)\n",
    "            \n",
    "            # Get AFTER ban data, same process as before\n",
    "            pytrends.build_payload([book_title], timeframe=after_timeframe, geo='US')\n",
    "            after_df = pytrends.interest_over_time()\n",
    "            \n",
    "            if not after_df.empty and book_title in after_df.columns:\n",
    "                after_values = after_df[book_title].values\n",
    "                after_avg = np.mean(after_values)\n",
    "                after_max = np.max(after_values)\n",
    "                after_min = np.min(after_values)\n",
    "            else:\n",
    "                after_avg = after_max = after_min = 0\n",
    "            \n",
    "            # Calculate metrics (comparing search popularity)\n",
    "            if before_avg > 0:\n",
    "                percent_change = ((after_avg - before_avg) / before_avg) * 100\n",
    "                absolute_change = after_avg - before_avg\n",
    "            else:\n",
    "                percent_change = 0 if after_avg == 0 else float('inf')\n",
    "                absolute_change = after_avg\n",
    "            \n",
    "            # Calculate volatility (standard deviation)\n",
    "            all_values = list(before_values) + list(after_values)\n",
    "            volatility = np.std(all_values) if len(all_values) > 0 else 0\n",
    "            \n",
    "            logging.info(f\"Successfully collected data for: {book_title}\")\n",
    "            \n",
    "            return {\n",
    "                'book_title': book_title,\n",
    "                'ban_date': ban_date_str,\n",
    "                'avg_search_before': round(before_avg, 2),\n",
    "                'avg_search_after': round(after_avg, 2),\n",
    "                'max_search_before': before_max,\n",
    "                'max_search_after': after_max,\n",
    "                'min_search_before': before_min,\n",
    "                'min_search_after': after_min,\n",
    "                'percent_change': round(percent_change, 2),\n",
    "                'absolute_change': round(absolute_change, 2),\n",
    "                'volatility': round(volatility, 2),\n",
    "                'data_collected': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'collection_successful': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed for {book_title}: {e}. Retrying...\")\n",
    "                time.sleep(20)  # Wait longer before retry\n",
    "            else:\n",
    "                logging.error(f\"All attempts failed for {book_title}: {e}\")\n",
    "                return {\n",
    "                    'book_title': book_title,\n",
    "                    'ban_date': ban_date_str,\n",
    "                    'avg_search_before': None,\n",
    "                    'avg_search_after': None,\n",
    "                    'max_search_before': None,\n",
    "                    'max_search_after': None,\n",
    "                    'min_search_before': None,\n",
    "                    'min_search_after': None,\n",
    "                    'percent_change': None,\n",
    "                    'absolute_change': None,\n",
    "                    'volatility': None,\n",
    "                    'data_collected': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'collection_successful': False,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "\n",
    "# TEST FUNCTION (Week 1)\n",
    "def test_collection():\n",
    "    \"\"\"Test the collection function with a few books\"\"\"\n",
    "    test_books = [\n",
    "        (\"Gender Queer\", \"2022-09-01\"),\n",
    "        (\"All Boys Aren't Blue\", \"2022-10-15\"),\n",
    "        (\"The Bluest Eye\", \"2022-08-20\")\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for title, date in test_books:\n",
    "        print(f\"Testing: {title}\")\n",
    "        result = get_trends_data(title, date)\n",
    "        results.append(result)\n",
    "        print(f\"Result: {result}\\n\")\n",
    "    \n",
    "    # Save test results\n",
    "    test_df = pd.DataFrame(results)\n",
    "    from pathlib import Path\n",
    "    # Ensure folder exists at the correct location (project root)\n",
    "    Path(\"../data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "    # Save CSV in project root data/raw folder\n",
    "    test_df.to_csv(\"../data/raw/test_results.csv\", index=False)\n",
    "    print(\"Test results saved to ../data/raw/test_results.csv\")\n",
    "\n",
    "\n",
    "# FULL COLLECTION FUNCTION (Week 2)\n",
    "def collect_all_books(input_csv='pen_america_banned_books.csv', output_csv='data/raw/google_trends_complete.csv'):\n",
    "    \"\"\"\n",
    "    Collect Google Trends data for all books in PEN America dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - input_csv: Path to PEN America CSV\n",
    "    - output_csv: Path to save results\n",
    "    \"\"\"\n",
    "    # Read input data\n",
    "    books_df = pd.read_csv(input_csv)\n",
    "    print(f\"Found {len(books_df)} books to process\")\n",
    "    \n",
    "    # Initialize results list\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each book with progress bar\n",
    "    for index, row in tqdm(books_df.iterrows(), total=len(books_df), desc=\"Collecting data\"):\n",
    "        book_title = row['Book Title']  # Adjust column name as needed\n",
    "        ban_date = row['Ban Date']       # Adjust column name as needed\n",
    "        \n",
    "        # Collect data\n",
    "        result = get_trends_data(book_title, ban_date)\n",
    "        if result:\n",
    "            result['state'] = row.get('State', 'Unknown')  # Add state if available\n",
    "            all_results.append(result)\n",
    "        \n",
    "        # Save progress every 10 books\n",
    "        if (index + 1) % 10 == 0:\n",
    "            temp_df = pd.DataFrame(all_results)\n",
    "            temp_df.to_csv(output_csv.replace('.csv', '_temp.csv'), index=False)\n",
    "            print(f\"\\nProgress saved: {index + 1}/{len(books_df)} books completed\")\n",
    "    \n",
    "    # Save final results\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== COLLECTION COMPLETE ===\")\n",
    "    print(f\"Total books processed: {len(results_df)}\")\n",
    "    print(f\"Successful collections: {results_df['collection_successful'].sum()}\")\n",
    "    print(f\"Failed collections: {(~results_df['collection_successful']).sum()}\")\n",
    "    print(f\"Average percent change: {results_df['percent_change'].mean():.2f}%\")\n",
    "    print(f\"Results saved to: {output_csv}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Week 1: Run test\n",
    "    print(\"Running test collection...\")\n",
    "    test_collection()\n",
    "    \n",
    "    # Week 2: Uncomment this to run full collection\n",
    "    # print(\"Running full collection...\")\n",
    "    # collect_all_books()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
